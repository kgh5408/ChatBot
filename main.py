"""
[git-streamlit ì—°ë™]
- https://yeomss.tistory.com/301

[streamlit ê°•ì˜]
- https://www.youtube.com/watch?v=ZVmLe3odQvc
- https://www.youtube.com/watch?v=VtS8yF2ItgI

"""
from langchain.schema import ChatMessage
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory
import yaml
import streamlit_authenticator as stauth
from utils import *
from documents import *
from langchain.prompts.chat import (
HumanMessagePromptTemplate,
SystemMessagePromptTemplate,
)
from langchain.chains import ConversationChain
from langchain.prompts import PromptTemplate
from streamlit.external.langchain import StreamlitCallbackHandler
import re
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv('api_key')
os.environ["OPENAI_API_KEY"] = api_key


st.set_page_config(page_title="ì „ì„¸ ì‚¬ê¸° ë°©ì§€ ChatBot", page_icon="ğŸ ")
st.title("ğŸ  ì „ì„¸ ì‚¬ê¸° ë°©ì§€ ChatBot")

# login (https://github.com/mkhorasani/Streamlit-Authenticator)
with open('config.yaml', encoding='utf-8') as file:
    config = yaml.load(file, Loader=stauth.SafeLoader)

authenticator = stauth.Authenticate(
    config['credentials'],
    config['cookie']['name'],
    config['cookie']['key'],
    config['cookie']['expiry_days'],
    # config['pre-authorized']
)

st.session_state['authentication_status'] = True  # !!!!!!!!!!! ë‚˜ì¤‘ì— ì§€ìš°ê¸°

if st.session_state['authentication_status'] is None:
    try:
        authenticator.login('main')
        if st.session_state['authentication_status']:
            st.rerun()  
    except Exception as e:
        st.error(e)
    # st.warning('Please enter your username and password')

elif st.session_state['authentication_status'] is False:
    st.error('Username/password is incorrect')

elif st.session_state['authentication_status']:
    markdown()

    if "messages" not in st.session_state:
        st.session_state['messages'] = []

    if "store" not in st.session_state:
        st.session_state["store"] = dict()

    if "uploaded_file" not in st.session_state:
        st.session_state["uploaded_file"] = None

    with st.sidebar:
        session_id = st.session_state["name"]

        st.write(f'ì‚¬ìš©ì - {st.session_state["name"]}')
        authenticator.logout()
        
        # ë“±ê¸°ë¶€ë“±ë³¸ ì—…ë¡œë“œ
        file_uploader_key = f"file_uploader_{st.session_state.get('reset_counter', 0)}"
        uploaded_files = st.file_uploader(
            label="ë“±ê¸°ë¶€ë“±ë³¸",
            type=list(DocumentLoader.supported_extenstions.keys()),
            accept_multiple_files=True,
            key=file_uploader_key,
        )
        st.session_state["uploaded_file"] = uploaded_files

        if not st.session_state["uploaded_file"]:
            st.info("ë“±ê¸°ë¶€ë“±ë³¸ì„ ì—…ë¡œë“œ í•˜ì„¸ìš”.")
            st.stop()

        # ë“±ê¸°ë¶€ë“±ë³¸ ë‚´ìš© ì¶”ì¶œ
        st.session_state["document1"] = extract_document1(st.session_state["uploaded_file"], type="full")

        # ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™”
        clear_btn = st.button("ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™”")
        if clear_btn:
            st.session_state['messages'] = []
            st.session_state["store"] = dict()
            st.session_state["uploaded_file"] = None
            if "reset_counter" not in st.session_state:
                st.session_state["reset_counter"] = 0
            st.session_state["reset_counter"] += 1
            st.rerun()

    # ì´ì „ ëŒ€í™”ê¸°ë¡ ì¶œë ¥ 
    print_messages()

    # ì²˜ìŒ ëŒ€í™” ë‚´ìš© ê³ ì • - ëŒ€í™” ë‚´ìš© ê³ ì •
    if (len(st.session_state['messages'])==0) & (st.session_state["uploaded_file"] is not None):
        # ì „ìš© ë©´ì  ì¶”ì¶œ
        area = 0
        for text in st.session_state["document1"].split("ê±´ ë¬¼ ë‚´ ì—­"):
            if "ã¡" in text:
                text2 = text.split("ëŒ€ì§€ê¶Œ")[0]
                numbers = re.findall(r'\s*(\d+\.?\d*\s?)ã¡', text2)
                for number in numbers:
                    area += float(number)
                break
        area = round(area, 4)

        user_input = f"""
            ë“±ê¸°ë¶€ë“±ë³¸:{st.session_state["document1"]} 
            
            ìœ„ ë“±ê¸°ë¶€ë“±ë³¸ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ë§í•´ì£¼ì„¸ìš”.
            
            [ë‹µë³€í˜•ì‹]
            ë³¸ ë“±ê¸°ë¶€ë“±ë³¸ì˜ ë‚´ìš©ì„ ì •ë¦¬í•˜ì—¬ ë§ì”€ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
            - ì§€ë²ˆ ì£¼ì†Œ:
            - ë‘ë¡œëª… ì£¼ì†Œ:
            - ì „ìš© ë©´ì : {area}ã¡
            - ì´ ê·¼ì €ë‹¹: 
            - ì‹ íƒ ì—¬ë¶€:
            - ì••ë¥˜ í˜„í™©:
            - ë“±ë“±
        """  # !!!!! ë‹µë³€í˜•ì‹ì„ ì§€ì •í•´ì£¼ë©´ ì¢‹ì„ë“¯!
        with st.chat_message("assistant"):
            stream_handler = StreamHandler(st.empty())
            llm = ChatOpenAI(streaming=True, callbacks=[stream_handler])
            prompt_template = """
                {chat_history}
                ì§ˆë¬¸: {input}
                ë‹µë³€:
            """
            conv_llm = ConversationChain(llm=llm, 
                                         memory=MEMORY,
                                         prompt=PromptTemplate(template=prompt_template, input_variables=["chat_history", "input"]))
            response = conv_llm.predict(input=user_input)
            st.session_state['messages'].append(
                ChatMessage(role='assistant', content=response)
            )

            # ì£¼ë³€ ì‹œì„¸ ì¶”ì¶œ
            doro_match = re.search(r"ë„ë¡œëª… ì£¼ì†Œ:\s*(.+)", response)
            address_doro = doro_match.group(1) if doro_match else None

            st.session_state["price"] = extreact_nearby_price(address_doro, area)

    user_input = st.chat_input("ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    if user_input:
        # ì‚¬ìš©ì ì…ë ¥
        st.chat_message("user").write(f"{user_input}")
        st.session_state['messages'].append(ChatMessage(role='user', content=user_input))
        
        # AI ë”¥ë³€
        assistant = st.chat_message("assistant")
        stream_handler = StreamlitCallbackHandler(assistant)
        # container = st.empty()
        with st.chat_message("assistant"):
            # 1. LLM ìƒì„±
            llm = ChatOpenAI(streaming=True)
            
            # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        # "ë“±ê¸°ë¶€ë“±ë³¸ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: {document}"
                        # "ì „ì„¸ì‚¬ê¸°ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì— ì¹œì ˆíˆ ë‹µë³€í•˜ì„¸ìš”."
                        "ë„ˆëŠ” ë¶€ë™ì‚° ì „ë¬¸ê°€ì•¼"
                    ),
                    # # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, historyê°€ MessageHistoryì˜ keyê°€ ë¨.
                    # MessagesPlaceholder(variable_name="history"),
                    ("human","{question}"),
                ]
            )
    
            system_message = SystemMessagePromptTemplate.from_template(
                f"ë³¸ ì§‘ì˜ ì£¼ë³€ ì‹œì„¸: {st.session_state['price']}ì›"+
                """
                ì°¸ê³  ë‚´ìš©: {context}
                ì´ì „ ëŒ€í™” ë‚´ìš©: {chat_history} 
                
                ë„ˆëŠ” ìœ„ ë‚´ìš©ì„ ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ë©´ ëœë‹¤.
                """
            )
            human_message = HumanMessagePromptTemplate.from_template(
                """
                {question}
                """
            )
            prompt = ChatPromptTemplate.from_messages([system_message, human_message])

            
            # 3. Chain ìƒì„±
            # # ì½˜í…ì¸  ê²€ì—´ ê¸°ëŠ¥ 
            # moderation = OpenAIModerationChain()
            # chain = prompt | llm | moderation

            conv_chain = configure_retrieval_chain(llm, prompt)

            response = conv_chain.run({"question": user_input, "chat_history": MEMORY.chat_memory.messages},
                                      callbacks=[stream_handler]
                                      )

            msg = response

            # chain_with_memory = (
            #     RunnableWithMessageHistory(
            #         chain,
            #         get_session_history_local,
            #         input_messages_key="input",  # ì‚¬ìš©ì ì§ˆë¬¸ í‚¤
            #         history_messages_key="history",  # ê¸°ë¡ ë©”ì„¸ì§€ í‚¤
            #     )
            # )
            
            # response = chain_with_memory.invoke(
            #     {"document": document1, "input": user_input},
            #     # {"input": user_input},
            #     config={"configurable": {"session_id": session_id}}
            # )

            # # msg = response.content
            # msg = response['output'].content  # OpenAIModerationChain ì‚¬ìš© ì‹œ

            # container.markdown(msg)
            st.write(msg)
            st.session_state['messages'].append(
                ChatMessage(role='assistant', content=msg)
            )






